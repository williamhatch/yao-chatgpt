---
created: 2023-02-15T20:09:06 (UTC +08:00)
tags: []
source: https://towardsdatascience.com/gpt-3-parameters-and-prompt-design-1a595dc5b405
author: Anthony Cavin
---

# GPT-3 Parameters and Prompt Design | by Anthony Cavin | Towards Data Science

> ## Excerpt
>
> GPT-3 is a computer system that is designed to generate natural language. It does this by taking in a piece of text and then predicting the next word or phrase that should come after it. In order to…

---

## Idea generator, instruction, and TL;DR summary

![](https://miro.medium.com/max/1050/0*wEL1QZqopLJ9IQbu)

Photo by [Roman Kraft](https://unsplash.com/@iamromankraft?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

GPT-3 is a computer system that is designed to generate natural language. It does this by taking in a piece of text and then predicting the next word or phrase that should come after it.

In order to accomplish this, GPT-3 uses a deep learning algorithm that has been trained on a large corpus of text. This allows it to capture the statistical patterns of how words are used together in a sentence.

GPT-3 can be used for a variety of tasks that involve natural language generation, such as machine translation, question answering, and text summaries. GPT-3 can even be used to generate new texts from scratch, such as stories or articles.

In this blog post, we will look at the parameters that we can set when using the model and go through a couple of [examples](https://beta.openai.com/examples) proposed by OpenAI.

## What are the parameters?

OpenAI GPT-3 is a machine learning model that can be used to generate predictive text via an API. OpenAI has different models that we can use, and the most capable one is called “text-davinci-002”.

To use the model, we can send API requests as follows.

```
curl https://api.openai.com/v1/completions \ -H “Content-Type: application/json” \ -H “Authorization: Bearer $OPENAI_API_KEY” \ -d ‘{ “model”: “text-davinci-002”, “prompt”: “What are 5 key points I should know when studying Ancient Rome?”, “temperature”: 0.3, “max_tokens”: 150, “top_p”: 1, “frequency_penalty”: 0, “presence_penalty”: 0}'
```

**Engine  
**The engine parameter specifies the AI model employed to generate predictions. In this article, we will use the most capable one: “text-davinci-002”.

**Max tokens  
**The “max tokens” parameter specifies the maximum number of tokens that can be generated by the model. A token can be seen as a piece of word.

> As a rule of thumb, 1 token is around 4 characters.

**Temperature  
**Before being mapped into probabilities, the model outputs unnormalized values (logits). The logits are typically used with a function such as softmax to convert them into probabilities.

But, before applying the softmax function, we can use a trick inspired by thermodynamics and scale the logits with the temperature parameter, i.e. softmax(logits/temperature).

A temperature parameter close to 1 would mean that the logits are passed through the softmax function without modification. If the temperature is close to zero, the highest probable tokens will become very likely compared to the other tokens, i.e. the model becomes more deterministic and will always output the same set of tokens after a given sequence of words.

> With a temperature between 0 and 1, we can control the randomness and creativity of the model’s predictions.

**Top p  
**The top p parameter specifies a sampling threshold during inference time. Top p sampling (sometimes called nucleus sampling) is a technique used to sample possible outcomes of the model.

To better understand this concept, let’s imagine that the model has to predict the next token after the sentence “I want to eat“. For simplicity, we will assume that a token is a word and that the model outputs the following probabilities:

- carrots (2% likely),
- cucumbers (1.5% likely),
- aubergines (1% likely),
- Spinach (0.5% likely),
- Broccoli (0.3% likely),
- …

This set of words forms a probability distribution “P( Word | “I want to eat“)” and the cumulative distribution function (CDF) would look as follows:

- 2% with carrots,
- 3.5% with carrots and cucumbers,
- 4.5% with carrots, cucumbers, and aubergines
- …

If we set the top p-parameter to 3.5%, the model will sample and randomly select between carrots and cucumbers according to their likelihood. With a top p at 4.5%, the model will randomly select a word between carrots, cucumbers, and aubergines.

Like the temperature, the top p parameter controls the randomness and originality of the model.

> Top p and temperature parameters both control the randomness of the model. OpenAI documentation recommends using either one parameter or the other and setting the unused parameter to the neutral case, i.e. 1.0.

**Frequency penalty  
**The frequency penalty parameter controls the model’s tendency to repeat predictions. The frequency penalty reduces the probability of words that have already been generated. The penalty depends on how many times a word has already occurred in the prediction.

**Presence penalty  
**The presence penalty parameter encourages the model to make novel predictions. The presence penalty lowers the probability of a word if it already appeared in the predicted text. Unlike the frequency penalty, the presence penalty does not depend on the frequency at which words appear in past predictions.

## **Grammar correction**

```
Engine: text-davinci-002Max tokens: 60Temperature: 0Top p: 1.0Frequency penalty: 0.0Presence penalty: 0.0
```

Technology has always been a boon for writers and students struggling with grammar. In the past, we had spell checkers and grammar checkers to help us catch mistakes. But now, even GPT-3 can do the work and catch errors.

This can be especially helpful for those who are non-native English speakers or who have difficulty with grammar.

**Prompt**

```
Correct this to standard English: I’m looking forward to see you
```

**Response**

```
I’m looking forward to seeing you.
```

So if you’re looking for a way to improve your writing, give GPT-3-powered grammar correction a try. You might be surprised at how much it can help.

## **Idea generator**

```
Engine: text-davinci-002Max tokens: 150Temperature: 0.6Top p: 1.0Frequency penalty: 1Presence penalty: 1
```

If you’re struggling to come up with fresh ideas, you may want to consider using GPT-3 as well.

For example, you could tell the AI to come up with ideas for a new product that is environmentally friendly. The AI would then generate a list of potential ideas for you to choose from.

**Prompt**

```
come up with ideas for a new product that is environmentally friendly:
```

**Response**

```
1. A reusable water bottle that can be refilled from the tap. 2. A reusable shopping bag made from recycled materials. 3. A solar-powered cell phone charger. 4. An LED light bulb that lasts for years and consumes very little energy.
```

You can also use GPT-3 to find solutions to problems you are facing. For example, if you’re trying to increase sales at your store, the AI could generate a list of marketing ideas for you to consider.

**Prompt**

```
brainstorm solutions to increase sales at your store:
```

**Response**

```
1. Offer discounts or coupons. 2. Host a sale or clearance event. 3. Create an attractive window display. 4. Place items on end caps or near the register. 5. Train staff to upsell and cross-sell products. 6. Implement a loyalty program. 7. Send out direct mailers or emails. 8. Place ads in local publications. 9. Sponsor a community event. 10. Get involved with social media marketing
```

So if you’re looking for a creative way to solve a problem, GPT-3 may be just what you need.

## **TL;DR summarization**

```
Engine: text-davinci-002Max tokens: 60
Temperature: 0.7
Top p: 1.0
Frequency penalty: 0.0
Presence penalty: 0.0
```

As anyone who spends time online knows, there is a lot of text out there. And sometimes, it can be hard to wade through all of it.

With TL;DR, you can quickly get the gist of a piece of text without having to read through all of it. And now, GPT-3 can do the work for you.

Just feed the tool the text you want to be summarized, and it will do its best to give you a concise overview.

**Prompt**

```
Technology has always been a boon for writers and students struggling with grammar. In the past, we had spell checkers and grammar checkers to help us catch mistakes. But now, even GPT-3 can do the work and catch errors.This can be especially helpful for those who are non-native English speakers or who have difficulty with grammar.Tl;dr
```

**Response**

```
If you’re struggling with your grammar, consider using an AI-powered grammar checker to help you improve your writing.
```

## Can we give additional instructions?

This part is probably the most fascinating one. We can “instruct” the algorithm on how to respond to requests by adding context to the prompt.

**Prompt**

```
my company produces reusable water bottles that can be refilled from the tap.brainstorm solutions to increase sales at your store:
```

**Response**

```
1. Offer a discount to customers who purchase your reusable water bottles. 2. Place your water bottles in high-traffic areas of your store so that more people will see them. 3. Educate your staff about the benefits of using reusable water bottles and encourage them to use them themselves. This will create a positive example for customers. 4. Make sure that your water bottles are easy to find and accessible in your store so that customers can easily grab one when they need it.
```

> The context that we added to the prompt was directly reflected in the response.

This behavior is expected as the model predicts the next tokens according to the ones given in the prompt.

Sometimes a single word can change the whole response. For instance, we can get a longer response if we use the word “summary” instead of “TL;DR”:

**Prompt**

```
Technology has always been a boon for writers and students struggling with grammar. In the past, we had spell checkers and grammar checkers to help us catch mistakes. But now, even GPT-3 can do the work and catch errors. This can be especially helpful for those who are non-native English speakers or who have difficulty with grammar. Summary:
```

**Response**

```
Technology has always been a boon for writers and students struggling with grammar. In the past, we had spell checkers and grammar checkers to help us catch mistakes. But now, even GPT-3 can do the work and catch errors.
```

## **Conclusion**

The GPT-3 computer system is designed to generate natural language by predicting the next word or phrase that should come after it. This deep learning algorithm has been trained on a large set of text, allowing it to capture the statistical patterns of how words are used together in a sentence.

GPT-3 is an excellent tool that we can use to come up with new ideas, correct grammar mistakes, and even generate texts. To get the most out of the model, we can play with the parameters, but we can also design the prompt in such a way that it leads the AI to the desired response.

Thanks for reading!
